# Gradiente Espelhado com DivergÃªncias de Bregman

Este arquivo implementa o algoritmo de **Gradiente Espelhado** (Mirror Descent) com divergÃªncias de Bregman para problemas de otimizaÃ§Ã£o nÃ£o-linear de larga escala, baseado na coleÃ§Ã£o de problemas de Liu e Nocedal (1989).

## ğŸ“‹ **FormulaÃ§Ã£o MatemÃ¡tica**

### **Problema de OtimizaÃ§Ã£o**
Considere o problema com restriÃ§Ãµes:
```
min f(x)
x âˆˆ C
```

onde `f: â„â¿ â†’ â„` Ã© uma funÃ§Ã£o diferenciÃ¡vel e `C âŠ† â„â¿` Ã© um conjunto convexo fechado.

### **Algoritmo de Gradiente Espelhado**

O algoritmo resolve iterativamente o problema:
```
x^{k+1} = argmin_{x âˆˆ C} {âŸ¨âˆ‡f(x^k), xâŸ© + (1/Î·_k) D_Ï†(x, x^k)}
```

onde:
- `âˆ‡f(x^k)` Ã© o gradiente da funÃ§Ã£o objetivo
- `Î·_k > 0` Ã© o tamanho do passo
- `D_Ï†(x, y)` Ã© a divergÃªncia de Bregman

### **DivergÃªncia de Bregman**
Para uma funÃ§Ã£o estritamente convexa `Ï†: â„â¿ â†’ â„`:
```
D_Ï†(x, y) = Ï†(x) - Ï†(y) - âŸ¨âˆ‡Ï†(y), x - yâŸ©
```

## ğŸ”§ **FunÃ§Ãµes Implementadas**

### **1. `calcular_gradiente(f, x)`**
```python
def calcular_gradiente(f, x):
    """
    Calcula gradiente numericamente usando diferenÃ§as finitas centrais
    
    Args:
        f: funÃ§Ã£o objetivo
        x: ponto atual
    
    Returns:
        grad: vetor gradiente
    """
```
**FÃ³rmula**: `âˆ‡f_i â‰ˆ [f(x + hÂ·e_i) - f(x - hÂ·e_i)] / (2h)`

### **2. DivergÃªncias de Bregman**

#### **`euclidean_phi(x)` e `euclidean_grad_phi(x)`**
```python
def euclidean_phi(x):
    """FunÃ§Ã£o potencial: Ï†(x) = (1/2)||x||Â²"""
    return 0.5 * np.sum(x**2)

def euclidean_grad_phi(x):
    """Gradiente: âˆ‡Ï†(x) = x"""
    return x
```

#### **`entropy_phi(x)` e `entropy_grad_phi(x)`**
```python
def entropy_phi(x):
    """FunÃ§Ã£o potencial: Ï†(x) = Î£áµ¢ xáµ¢ log(xáµ¢)"""
    x_safe = np.maximum(x, 1e-10)
    return np.sum(x_safe * np.log(x_safe))

def entropy_grad_phi(x):
    """Gradiente: âˆ‡Ï†(x) = 1 + log(x)"""
    x_safe = np.maximum(x, 1e-10)
    return 1 + np.log(x_safe)
```

#### **`p_norm_phi(x, p=2)` e `p_norm_grad_phi(x, p=2)`**
```python
def p_norm_phi(x, p=2):
    """FunÃ§Ã£o potencial: Ï†(x) = (1/p)||x||áµ–áµ–"""
    return (1/p) * np.sum(np.abs(x)**p)

def p_norm_grad_phi(x, p=2):
    """Gradiente: âˆ‡Ï†(x) = sign(x) * |x|^(p-1)"""
    return np.sign(x) * (np.abs(x) ** (p - 1))
```

### **3. `gradiente_espelhado(f, x0, eta_inicial, max_iter, tol, bregman, bounds, p)`**
```python
def gradiente_espelhado(f, x0, eta_inicial=0.01, max_iter=1000, tol=1e-6, 
                       bregman="euclidean", bounds=None, p=2):
    """
    Algoritmo de Gradiente Espelhado com passo adaptativo
    
    Args:
        f: funÃ§Ã£o objetivo
        x0: ponto inicial
        eta_inicial: passo inicial
        max_iter: mÃ¡ximo de iteraÃ§Ãµes
        tol: tolerÃ¢ncia para convergÃªncia
        bregman: tipo de divergÃªncia ("euclidean", "entropy", "p_norm")
        bounds: tipo de restriÃ§Ã£o
        p: parÃ¢metro para norma-p
    
    Returns:
        x: ponto Ã³timo
        fo: valor da funÃ§Ã£o objetivo
        k: nÃºmero de iteraÃ§Ãµes
    """
```

**CaracterÃ­sticas**:
- Passo adaptativo baseado na melhoria da funÃ§Ã£o
- MÃºltiplas divergÃªncias de Bregman
- ProjeÃ§Ãµes automÃ¡ticas para diferentes restriÃ§Ãµes

### **4. AtualizaÃ§Ãµes por Tipo de DivergÃªncia**

#### **DivergÃªncia Euclidiana**
```python
if bregman == "euclidean":
    x_new = x - eta * grad_f
    # ProjeÃ§Ã£o na bola unitÃ¡ria se necessÃ¡rio
    if constraint_type == "ball":
        x_norm = np.linalg.norm(x_new)
        if x_norm > 1.0:
            x_new = x_new / x_norm * 0.99
```

#### **DivergÃªncia de Entropia**
```python
elif bregman == "entropy":
    x_safe = np.maximum(x, 1e-10)
    x_new = np.exp(np.log(x_safe) - eta * grad_f)
    # NormalizaÃ§Ã£o para simplex se necessÃ¡rio
    if constraint_type == "simplex":
        x_new = x_new / np.sum(x_new)
```

#### **DivergÃªncia Norma-p**
```python
elif bregman == "p_norm":
    if p == 2:
        x_new = x - eta * grad_f
    else:
        grad_phi_x = p_norm_grad_phi(x, p)
        grad_phi_new = grad_phi_x - eta * grad_f
        x_new = np.sign(grad_phi_new) * (np.abs(grad_phi_new) ** (1 / (p - 1)))
```

### **5. Controle Adaptativo do Passo**
```python
# Verificar melhoria
improvement = fo - fo_new

if improvement > 1e-8:
    # Boa melhoria: aceitar e aumentar passo
    x = x_new
    fo = fo_new
    eta = min(eta * 1.2, 2.0)
else:
    # Pouca melhoria: diminuir passo
    eta = eta * 0.15
    if k - last_improvement > 5:
        eta = max(eta, 1e-8)
```

## ğŸ—ï¸ **Classe Principal**

### **`MirrorGradientOptimizedSolver`**

```python
class MirrorGradientOptimizedSolver:
    def __init__(self, eta=0.01, bregman="euclidean", p=2):
        """
        Inicializa o solver com gradiente espelhado adaptativo
        
        Args:
            eta: parÃ¢metro de passo inicial
            bregman: tipo de divergÃªncia de Bregman
            p: parÃ¢metro para norma-p
        """
    
    def solve_problem(self, problem_name, max_iter=1000, tol=1e-6):
        """
        Resolve um problema especÃ­fico
        
        Returns:
            dict: resultados da otimizaÃ§Ã£o
        """
    
    def solve_all_problems(self, max_iter=1000, tol=1e-6):
        """
        Resolve todos os problemas configurados
        """
    
    def print_summary(self):
        """
        Imprime resumo dos resultados
        """
    
    def _determine_constraint_type(self, problem_name, bounds):
        """
        Determina o tipo de restriÃ§Ã£o apropriado para cada problema
        """
```

## ğŸ“Š **Estrutura dos Resultados**

Cada resultado contÃ©m:
```python
{
    'problem': str,           # Nome do problema
    'success': bool,          # Sucesso da otimizaÃ§Ã£o
    'iterations': int,        # NÃºmero de iteraÃ§Ãµes
    'function_value': float,  # Valor mÃ­nimo encontrado
    'x_value': array,         # Ponto Ã³timo
    'gradient_norm': float,   # Norma do gradiente final
    'message': str,           # Mensagem de status
    'execution_time': float,  # Tempo de execuÃ§Ã£o
    'n_variables': int,       # NÃºmero de variÃ¡veis
    'constraint_type': str    # Tipo de restriÃ§Ã£o aplicada
}
```

## ğŸš€ **Como Usar**

### **Exemplo BÃ¡sico**
```python
from mirror_gradient_optimized import MirrorGradientOptimizedSolver

# Criar solver com divergÃªncia euclidiana
solver = MirrorGradientOptimizedSolver(eta=0.01, bregman="euclidean", p=2)

# Resolver um problema especÃ­fico
result = solver.solve_problem('ROSENBROCK', max_iter=1000, tol=1e-6)

# Resolver todos os problemas
solver.solve_all_problems()
solver.print_summary()
```

### **Exemplos com Diferentes DivergÃªncias**
```python
# DivergÃªncia euclidiana
solver_euclidean = MirrorGradientOptimizedSolver(eta=0.01, bregman="euclidean", p=2)

# DivergÃªncia de entropia
solver_entropy = MirrorGradientOptimizedSolver(eta=0.1, bregman="entropy", p=2)

# DivergÃªncia norma-p
solver_pnorm = MirrorGradientOptimizedSolver(eta=0.01, bregman="p_norm", p=2)
```

### **ExecuÃ§Ã£o Completa**
```bash
cd liu_nocedal
python mirror_gradient_optimized.py
```

## âš™ï¸ **ParÃ¢metros ConfigurÃ¡veis**

| ParÃ¢metro | PadrÃ£o | DescriÃ§Ã£o |
|-----------|--------|-----------|
| `eta` | 0.01 | Passo inicial |
| `bregman` | "euclidean" | Tipo de divergÃªncia |
| `p` | 2 | ParÃ¢metro para norma-p |
| `max_iter` | 1000 | MÃ¡ximo de iteraÃ§Ãµes |
| `tol` | 1e-6 | TolerÃ¢ncia para convergÃªncia |

## ğŸ¯ **Tipos de DivergÃªncias**

### **Euclidiana** (`bregman="euclidean"`)
- **FunÃ§Ã£o**: `Ï†(x) = (1/2)||x||Â²`
- **Uso**: Problemas gerais sem restriÃ§Ãµes especÃ­ficas
- **ProjeÃ§Ã£o**: Bola unitÃ¡ria

### **Entropia** (`bregman="entropy"`)
- **FunÃ§Ã£o**: `Ï†(x) = Î£áµ¢ xáµ¢ log(xáµ¢)`
- **Uso**: Problemas no simplex ou com variÃ¡veis positivas
- **ProjeÃ§Ã£o**: Simplex

### **Norma-p** (`bregman="p_norm"`)
- **FunÃ§Ã£o**: `Ï†(x) = (1/p)||x||áµ–áµ–`
- **Uso**: Problemas com geometria especÃ­fica
- **ProjeÃ§Ã£o**: Bola p-norma

## ğŸ”§ **Tipos de RestriÃ§Ãµes**

### **Bola UnitÃ¡ria** (`constraint_type="ball"`)
```python
x_norm = np.linalg.norm(x_new)
if x_norm > 1.0:
    x_new = x_new / x_norm * 0.99
```

### **Simplex** (`constraint_type="simplex"`)
```python
x_new = x_new / np.sum(x_new)
```

### **Caixa** (`constraint_type="box"`)
```python
for i, (lower, upper) in enumerate(bounds):
    x_new[i] = np.clip(x_new[i], lower, upper)
```

## ğŸ“ˆ **Vantagens do Algoritmo**

1. **Adaptabilidade**: Diferentes geometrias do espaÃ§o de otimizaÃ§Ã£o
2. **Controle AutomÃ¡tico**: Passo adaptativo baseado na melhoria
3. **EficiÃªncia**: Especializado para restriÃ§Ãµes especÃ­ficas
4. **Robustez**: Funciona bem em problemas mal condicionados
5. **Flexibilidade**: MÃºltiplas divergÃªncias de Bregman

## ğŸ” **Complexidade Computacional**

- **Por iteraÃ§Ã£o**: O(n) - cÃ¡lculo do gradiente e atualizaÃ§Ã£o
- **Total**: O(KÂ·n) onde K Ã© o nÃºmero de iteraÃ§Ãµes
- **MemÃ³ria**: O(n) - apenas o vetor de variÃ¡veis

## ğŸ“‹ **Problemas Suportados**

O algoritmo resolve todos os problemas da coleÃ§Ã£o Liu e Nocedal com restriÃ§Ãµes automÃ¡ticas:
- **Rosenbrock**: Bola unitÃ¡ria
- **Extended Rosenbrock**: Bola unitÃ¡ria
- **Extended Powell**: Bola unitÃ¡ria
- **Freudenthal-Roth**: Bola unitÃ¡ria
- **Engvall**: Bola unitÃ¡ria
- **Trigonometric**: Simplex
- **Penalty**: Bola unitÃ¡ria
- **ULTS0**: RestriÃ§Ãµes de caixa

## ğŸ“„ **SaÃ­das Geradas**

- **Tabela resumida**: EstatÃ­sticas gerais dos problemas
- **Tabela detalhada**: Valores das variÃ¡veis em mÃºltiplas colunas
- **PDFs**: Gerados automaticamente via LaTeX
- **Logs**: Progresso da otimizaÃ§Ã£o no console

## ğŸ“ **ReferÃªncias TeÃ³ricas**

- **Mirror Descent**: Nemirovski & Yudin (1983)
- **DivergÃªncias de Bregman**: Bregman (1967)
- **Problemas de Teste**: Liu & Nocedal (1989)
